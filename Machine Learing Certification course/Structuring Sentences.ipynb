{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pathogs='C:\\Program Files\\gs\\gs9.54.0\\bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH']+=os.pathsep+pathogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('dataset\\Tweets.csv')\n",
    "df=df[['text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "r=re.compile(r\"([@])(\\w+)\\b\")\n",
    "AllReferences=map(lambda x : r.findall(x),df['text'])\n",
    "\n",
    "import itertools\n",
    "AlluniqueReferences=set(list(itertools.chain.from_iterable(AllReferences)))\n",
    "References=map(lambda x:x[0]+x[1],AlluniqueReferences)\n",
    "\n",
    "file=open('References.txt','a')\n",
    "for each in References:\n",
    "    file.write(each+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def GetNounPhases(s):\n",
    "    try:\n",
    "        sentences=nltk.sent_tokenize(s)\n",
    "        sentences=[nltk.word_tokenize(sent) for sent in sentences]\n",
    "        sentences=[nltk.pos_tag(sent)for sent in sentences]\n",
    "    except:\n",
    "        return []\n",
    "    else:\n",
    "        grammar =r\"NP:{<DT><NN|NNS|NNP|NNPS>*<NN|NNS|NNP|NNPS>}\"\n",
    "\n",
    "        cp=nltk.RegexpParser(grammar)\n",
    "        noun_phrases_list=[[''.join(leaf[0] for leaf in tree.leaves())\n",
    "                           for tree in cp.parse(sent).subtrees()\n",
    "                           if tree.label()==\"NP\"]\n",
    "                           for sent in sentences]\n",
    "        return noun_phrases_list\n",
    "import itertools\n",
    "\n",
    "for group,sub in df.groupby('airline_sentiment'):\n",
    "    noun_phrases=map(lambda x: GetNounPhases(x),sub['text'])\n",
    "    noun_phrases=list(itertools.chain.from_iterable(noun_phrases))\n",
    "    AllNounPhases=set(list(itertools.chain.from_iterable(noun_phrases)))\n",
    "    filename=\"Noun Phases for \"+str(group)+\"Rewiew .txt\"\n",
    "    file = open(filename,'a')\n",
    "    for each in AllNounPhases:\n",
    "        file.write(each+\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
